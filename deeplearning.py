import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow as tf
layers = tf.keras.layers
import cv2
import os 

# 1.- Configuraci칩n del dataset y par치metros
IMG_SIZE = 224  # Tama침o de la imagen (224x224 p칤xeles) para redimensionar
BATCH_SIZE = 32 # N칰mero de im치genes que la IA procesa a la vez
SEED = 42       # Semilla para la reproducibilidad de las divisiones del dataset

DATASET_DIR = 'C:/Users/kjime/OneDrive/Documentos/archive/Apparel images dataset new'

def load_data():
    """
    Carga el dataset de im치genes de ropa desde el directorio especificado.
    Divide el dataset en conjuntos de entrenamiento y validaci칩n,
    y aplica la normalizaci칩n de p칤xeles.
    """
    # Verifica si el directorio del dataset existe
    if not os.path.exists(DATASET_DIR):
        print(f"Error: El directorio del dataset no se encontr칩 en '{DATASET_DIR}'.")
        print("Aseg칰rate de que la ruta sea correcta y que el dataset est칠 descomprimido en esa ubicaci칩n.")
        print("El script espera que las im치genes est칠n organizadas en subcarpetas, donde cada subcarpeta es una clase (ej. 'Apparel images dataset new/blue_pants/', 'Apparel images dataset new/t_shirt/', etc.).")
        # Si el directorio no existe, se lanza una excepci칩n para detener la ejecuci칩n.
        raise FileNotFoundError(f"Dataset directory not found: {DATASET_DIR}")

    print(f"Cargando datos desde: {DATASET_DIR}")
    
    # Carga el dataset de entrenamiento
    train_ds = tf.keras.utils.image_dataset_from_directory(
        DATASET_DIR,
        labels='inferred',         # Infiere las etiquetas de los nombres de las subcarpetas
        label_mode='int',          # Etiquetas como enteros (0, 1, 2, ...)
        image_size=(IMG_SIZE, IMG_SIZE), # Redimensiona las im치genes al tama침o deseado
        interpolation='bilinear',  # M칠todo de interpolaci칩n para el redimensionamiento
        batch_size=BATCH_SIZE,     # Tama침o del lote
        shuffle=True,              # Mezcla los datos
        seed=SEED,                 # Semilla para la mezcla y la divisi칩n
        validation_split=0.2,      # 80% para entrenamiento
        subset='training'          # Especifica que es el subconjunto de entrenamiento
    )
    
    # Carga el dataset de prueba/validaci칩n
    test_ds = tf.keras.utils.image_dataset_from_directory(
        DATASET_DIR,
        labels='inferred',
        label_mode='int',
        image_size=(IMG_SIZE, IMG_SIZE),
        interpolation='bilinear',
        batch_size=BATCH_SIZE,
        shuffle=True,
        seed=SEED,
        validation_split=0.2,      # 20% para validaci칩n/prueba
        subset='validation'        # Especifica que es el subconjunto de validaci칩n
    )
    
    # Obtiene los nombres de las clases inferidos del directorio
    class_names = train_ds.class_names
    print(f"Clases detectadas: {class_names}")
    print(f"N칰mero de clases: {len(class_names)}")

    # Crea una capa de normalizaci칩n para escalar los valores de los p칤xeles de 0-255 a 0-1
    normalization_layer = layers.Rescaling(1./255)
    
    # Aplica la normalizaci칩n y prefetch para optimizar el rendimiento de la carga de datos
    # Se utiliza num_parallel_calls para procesar elementos del dataset en paralelo en la CPU
    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)

    return train_ds, test_ds, class_names

# Carga los datos al inicio del script
train_ds, test_ds, class_names = load_data()

# 3.- Mostrar datos del dataset (9 im치genes aleatorias con sus etiquetas)
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1): # Toma un lote de im치genes del dataset de entrenamiento
    for i in range(9): # Muestra las primeras 9 im치genes del lote
        ax = plt.subplot(3, 3, i + 1) # Organiza las im치genes en una cuadr칤cula de 3x3
        plt.imshow(images[i].numpy()) # Muestra la imagen (ya normalizada)
        
        # Aseg칰rate de que el 칤ndice de la etiqueta est칠 dentro del rango de class_names
        if labels[i].numpy() < len(class_names):
            plt.title(class_names[labels[i].numpy()]) # Muestra la categor칤a
        else:
            plt.title(f"Etiqueta fuera de rango: {labels[i].numpy()}") # Mensaje de depuraci칩n si la etiqueta es inv치lida
        plt.axis('off') # Oculta los ejes para una visualizaci칩n m치s limpia
plt.show()

# 4.- Construir el modelo de red neuronal (versi칩n simplificada para entrenamiento m치s r치pido)
def build_model(num_classes):
    """
    Construye el modelo de red neuronal utilizando EfficientNetB0 como modelo base
    para 'transfer learning', incluyendo capas de aumento de datos y dropout.
    El modelo base es entrenable desde el principio con una tasa de aprendizaje baja.
    """
    # Capas de aumento de datos: se aplican en cada 칠poca al dataset de entrenamiento
    data_augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal"), # Voltea im치genes horizontalmente de forma aleatoria
        layers.RandomRotation(0.1),      # Rota im치genes en un rango de +/- 10%
        layers.RandomZoom(0.1),          # Aplica un zoom aleatorio en un rango de +/- 10%
    ], name="data_augmentation")

    # Carga el modelo EfficientNetB0 pre-entrenado en ImageNet
    base_model = tf.keras.applications.EfficientNetB0(
        include_top=False,  # No incluye la capa clasificadora superior (la a침adiremos nosotros)
        weights='imagenet', # Usa los pesos pre-entrenados de ImageNet
        input_shape=(IMG_SIZE, IMG_SIZE, 3) # Define la forma de la entrada (altura, ancho, canales RGB)
    )
    
    # El modelo base se hace entrenable desde el principio para permitir un ajuste fino.
    # La tasa de aprendizaje baja en el optimizador se encargar치 de que los cambios sean graduales.
    base_model.trainable = True 

    # Crea el modelo completo: aumento de datos + modelo base + cabezal de clasificaci칩n
    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = data_augmentation(inputs) # Aplica el aumento de datos
    x = base_model(x) # Pasa la salida a EfficientNetB0
    x = layers.GlobalAveragePooling2D()(x) # Reduce dimensiones
    x = layers.Dropout(0.5)(x) # Capa Dropout para reducir el sobreajuste
    outputs = layers.Dense(num_classes, activation='softmax')(x) # Capa de salida con activaci칩n softmax

    model = tf.keras.Model(inputs, outputs)
    
    return model

# Construye el modelo, pasando el n칰mero de clases detectadas
model = build_model(len(class_names))

# 5.- Compilar y entrenar el modelo (una sola fase, con tasa de aprendizaje baja para fine-tuning)
print("\n--- Iniciando Entrenamiento del Modelo (m치s b치sico y r치pido) ---")
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), # Tasa de aprendizaje baja para un ajuste fino gradual
    loss='sparse_categorical_crossentropy',                 # Funci칩n de p칠rdida para clasificaci칩n multiclase
    metrics=['accuracy']                                    # M칠trica para evaluar el rendimiento
)

# Menos 칠pocas para un entrenamiento m치s r치pido
total_epochs = 5 
history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=total_epochs,
    verbose=1 # Muestra el progreso del entrenamiento
)
print("Entrenamiento completado.")

# 6.- Evaluar el modelo
# Eval칰a el rendimiento final del modelo en el conjunto de prueba
test_loss, test_acc = model.evaluate(test_ds)
print(f"\n游댍 Precisi칩n en test: {test_acc*100:.2f}%")

# Gr치ficas de entrenamiento (para una sola fase de entrenamiento)
plt.figure(figsize=(12, 4))

# Gr치fico de precisi칩n
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Precisi칩n de Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisi칩n de Validaci칩n')
plt.title('Precisi칩n durante el Entrenamiento')
plt.xlabel('칄poca')
plt.ylabel('Precisi칩n')
plt.legend()

# Gr치fico de p칠rdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='P칠rdida de Entrenamiento')
plt.plot(history.history['val_loss'], label='P칠rdida de Validaci칩n')
plt.title('P칠rdida durante el Entrenamiento')
plt.xlabel('칄poca')
plt.ylabel('P칠rdida')
plt.legend()
plt.show()

# 8.- Funci칩n para reconocimiento en tiempo real desde la c치mara
def recognize_from_webcam(model, class_names, img_size):
    """
    Realiza el reconocimiento de ropa en tiempo real utilizando la c치mara web.
    """
    cap = cv2.VideoCapture(0) # Intenta abrir la c치mara predeterminada (칤ndice 0)
    if not cap.isOpened():
        print("Error: No se pudo abrir la c치mara. Intentando otros 칤ndices...")
        # Intenta otros 칤ndices de c치mara si el 0 falla
        for i in range(1, 5): # Prueba hasta 4 칤ndices adicionales (1, 2, 3, 4)
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                print(f"C치mara en 칤ndice {i} abierta correctamente.")
                break
        else: # Este else se ejecuta si el bucle for termina sin un 'break'
            print("Error: No se encontr칩 ninguna c치mara disponible o no se pudo abrir. Aseg칰rate de que no est칠 en uso y que los controladores est칠n instalados.")
            return # Sale de la funci칩n si no se puede abrir ninguna c치mara

    print("\n--- Reconocimiento de Ropa en Tiempo Real ---")
    print("Presiona 'q' para salir de la ventana de la c치mara.")

    while True:
        ret, frame = cap.read() # Lee un fotograma de la c치mara
        if not ret:
            print("Error: No se pudo leer el fotograma. Saliendo...")
            break

        # Voltea el fotograma horizontalmente para una visualizaci칩n m치s natural (como un espejo)
        frame = cv2.flip(frame, 1)

        # Preprocesamiento del fotograma para la predicci칩n del modelo
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Convierte de BGR (OpenCV) a RGB (TensorFlow)
        resized_frame = tf.image.resize(rgb_frame, (img_size, img_size)) # Redimensiona
        normalized_frame = tf.cast(resized_frame, tf.float32) / 255.0 # Normaliza a [0, 1]
        input_tensor = np.expand_dims(normalized_frame, axis=0) # A침ade una dimensi칩n de lote (Batch: 1, H, W, C)

        # Realiza la predicci칩n con el modelo
        preds = model.predict(input_tensor, verbose=0) # verbose=0 suprime la salida de la predicci칩n
        predicted_class_idx = np.argmax(preds) # Obtiene el 칤ndice de la clase con mayor probabilidad
        
        # Aseg칰rate de que el 칤ndice predicho est칠 dentro del rango de las clases conocidas
        if predicted_class_idx < len(class_names):
            predicted_class_name = class_names[predicted_class_idx] # Obtiene el nombre de la clase
            confidence = np.max(preds) * 100 # Calcula la confianza de la predicci칩n
        else:
            predicted_class_name = "Clase Desconocida" # Manejo de 칤ndice fuera de rango
            confidence = 0.0
            print(f"Advertencia: 칈ndice de clase predicho fuera de rango: {predicted_class_idx}")

        # Formatea el texto a mostrar en la ventana de la c치mara
        text = f"Prediccion: {predicted_class_name} ({confidence:.2f}%)"
        # print(text) # Puedes descomentar esto para ver las predicciones en la consola

        # Dibuja el texto en el fotograma original (en formato BGR)
        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.imshow('Reconocimiento de Ropa en Tiempo Real', frame) # Muestra el fotograma con la predicci칩n

        # Sale del bucle si se presiona la tecla 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Libera los recursos de la c치mara y cierra todas las ventanas de OpenCV
    cap.release()
    cv2.destroyAllWindows()

# Llama a la funci칩n de reconocimiento en tiempo real despu칠s de que el modelo ha sido entrenado
recognize_from_webcam(model, class_names, IMG_SIZE)